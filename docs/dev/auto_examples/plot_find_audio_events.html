<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Use Audio to Align Video Data &#8212; pd-parser v0.8dev0 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          pd-parser v0.8dev0</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Examples</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="../generated/cli.html">CLI</a></li>
                <li><a href="../whats_new.html">What's new</a></li>
                <li><a href="https://github.com/alexrockhill/pd-parser">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/auto_examples/plot_find_audio_events.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-find-audio-events-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="use-audio-to-align-video-data">
<span id="sphx-glr-auto-examples-plot-find-audio-events-py"></span><h1>Use Audio to Align Video Data<a class="headerlink" href="#use-audio-to-align-video-data" title="Permalink to this headline">¶</a></h1>
<p>In this example, we use <code class="docutils literal notranslate"><span class="pre">pd-parser</span></code> to find audio events using the same
algorithm for matching with time-stamps and rejecting misaligned
audio, but applied using the onset of an audio deflection instead of detecting
photodiode events based on their square wave shape.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Alex Rockhill &lt;aprockhill@mailbox.org&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>
</pre></div>
</div>
<p>Load in a video with audio</p>
<p>In this example, we’ll use audio and instead of aligning electrophysiology
data, we’ll align a video. This example data is from a task where movements
are played on a monitor for the participant to mirror and the video recording
is synchronized by playing a pre-recorded clap. This clap sound, or a similar
sound, is recommended for synchronizing audio because the onset is clear and
allows good precision in synchronizing events.</p>
<p>Note that the commands that require ffmpeg are pre-computed and commented
out because ffmpeg must be installed to use them and it is not required by
<code class="docutils literal notranslate"><span class="pre">pd-parser</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">op</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">wavfile</span>
<span class="kn">from</span> <span class="nn">subprocess</span> <span class="kn">import</span> <span class="n">call</span>
<span class="c1"># from subprocess import run, PIPE, STDOUT</span>
<span class="c1"># import datetime</span>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">mne.utils</span> <span class="kn">import</span> <span class="n">_TempDir</span>

<span class="kn">import</span> <span class="nn">pd_parser</span>

<span class="c1"># get the data</span>
<span class="n">out_dir</span> <span class="o">=</span> <span class="n">_TempDir</span><span class="p">()</span>
<span class="n">call</span><span class="p">([</span><span class="s1">&#39;curl -L https://raw.githubusercontent.com/alexrockhill/pd-parser/&#39;</span>
      <span class="s1">&#39;master/pd_parser/tests/data/test_video.mp4 &#39;</span>
      <span class="s1">&#39;-o &#39;</span> <span class="o">+</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;test_video.mp4&#39;</span><span class="p">)],</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>
<span class="n">call</span><span class="p">([</span><span class="s1">&#39;curl -L https://raw.githubusercontent.com/alexrockhill/pd-parser/&#39;</span>
      <span class="s1">&#39;master/pd_parser/tests/data/test_video.wav &#39;</span>
      <span class="s1">&#39;-o &#39;</span> <span class="o">+</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;test_video.wav&#39;</span><span class="p">)],</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>
<span class="n">call</span><span class="p">([</span><span class="s1">&#39;curl -L https://raw.githubusercontent.com/alexrockhill/pd-parser/&#39;</span>
      <span class="s1">&#39;master/pd_parser/tests/data/test_video_beh.tsv &#39;</span>
      <span class="s1">&#39;-o &#39;</span> <span class="o">+</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;test_video_beh.tsv&#39;</span><span class="p">)],</span>
     <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>

<span class="c1"># navigate to the example video</span>
<span class="n">video_fname</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;test_video.mp4&#39;</span><span class="p">)</span>

<span class="n">audio_fname</span> <span class="o">=</span> <span class="n">video_fname</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;mp4&#39;</span><span class="p">,</span> <span class="s1">&#39;wav&#39;</span><span class="p">)</span>  <span class="c1"># pre-computed</span>
<span class="c1"># extract audio (requires ffmpeg)</span>
<span class="c1"># run([&#39;ffmpeg&#39;, &#39;-i&#39;, video_fname, audio_fname])</span>

<span class="n">fs</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">wavfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">audio_fname</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># stereo audio but only need one source</span>
<span class="n">info</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">create_info</span><span class="p">([</span><span class="s1">&#39;audio&#39;</span><span class="p">],</span> <span class="n">fs</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;stim&#39;</span><span class="p">])</span>
<span class="n">raw</span> <span class="o">=</span> <span class="n">mne</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">RawArray</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">info</span><span class="p">)</span>

<span class="c1"># find audio-visual time offset</span>
<span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># pre-computed value for this video</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">result = run([&#39;ffprobe&#39;, &#39;-show_entries&#39;, &#39;stream=codec_type,start_time&#39;,</span>
<span class="sd">              &#39;-v&#39;, &#39;0&#39;, &#39;-of&#39;, &#39;compact=p=1:nk=0&#39;, video_fname],</span>
<span class="sd">             stdout=PIPE, stderr=STDOUT)</span>
<span class="sd">output = result.stdout.decode(&#39;utf-8&#39;).split(&#39;\n&#39;)</span>
<span class="sd">offset = float(output[0].strip(&#39;stream|codec_type=video|start_time&#39;)) - \</span>
<span class="sd">    float(output[1].strip(&#39;stream|codec_type=audio|start_time&#39;))</span>
<span class="sd">&#39;&#39;&#39;</span>

<span class="c1"># save to disk as required by ``pd-parser``, raw needs a filename</span>
<span class="n">fname</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;sub-1_task-mytask_raw.fif&#39;</span><span class="p">)</span>
<span class="n">raw</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

<span class="c1"># navigate to corresponding behavior</span>
<span class="n">behf</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="s1">&#39;test_video_beh.tsv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Creating RawArray with float64 data, n_channels=1, n_times=16464896
    Range : 0 ... 16464895 =      0.000 ...   343.019 secs
Ready.
Writing /var/folders/s4/y1vlkn8d70jfw7s8s03m9p540000gn/T/tmp_mne_tempdir_ran50pv8/sub-1_task-mytask_raw.fif
Closing /var/folders/s4/y1vlkn8d70jfw7s8s03m9p540000gn/T/tmp_mne_tempdir_ran50pv8/sub-1_task-mytask_raw.fif
[done]
</pre></div>
</div>
<p>Run the parser</p>
<p>Now we’ll call the main function to automatically parse the audio events.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">annot</span><span class="p">,</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">pd_parser</span><span class="o">.</span><span class="n">parse_audio</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">beh</span><span class="o">=</span><span class="n">behf</span><span class="p">,</span>
                                       <span class="n">beh_key</span><span class="o">=</span><span class="s1">&#39;tone_onset_time&#39;</span><span class="p">,</span>
                                       <span class="n">audio_ch_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;audio&#39;</span><span class="p">],</span> <span class="n">zscore</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<img alt="Synchronization Events Compared to Behavior Events" class="sphx-glr-single-img" src="../_images/sphx_glr_plot_find_audio_events_001.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Reading in /var/folders/s4/y1vlkn8d70jfw7s8s03m9p540000gn/T/tmp_mne_tempdir_ran50pv8/sub-1_task-mytask_raw.fif
Opening raw data file /var/folders/s4/y1vlkn8d70jfw7s8s03m9p540000gn/T/tmp_mne_tempdir_ran50pv8/sub-1_task-mytask_raw.fif...
Isotrak not found
    Range : 0 ... 16464895 =      0.000 ...   343.019 secs
Ready.
Reading 0 ... 16464895  =      0.000 ...   343.019 secs...
Finding points where the audio is above `zscore` threshold...
17 audio candidate events found
Checking best alignments

  0%|          | 0/15 [00:00&lt;?, ?it/s]
 53%|#####3    | 8/15 [00:00&lt;00:00, 76.93it/s]
100%|##########| 15/15 [00:00&lt;00:00, 82.61it/s]
Best alignment is with the first behavioral event shifted 0.01 s relative to the first synchronization event and has errors: min -6.65 ms, q1 -3.27 ms, med -0.58 ms, q3 3.99 ms, max 11.60 ms, 0 missed events
Excluding events that have zero close synchronization events or more than one synchronization event within `max_len` time
</pre></div>
</div>
<p>Load the results</p>
<p>Finally, we’ll load the events and use them to crop the video although it
requires ffmpeg so it is commented out.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Here are the event times: &#39;</span><span class="p">,</span> <span class="n">annot</span><span class="o">.</span><span class="n">onset</span><span class="p">)</span>

<span class="c1"># Crop the videos with ffmpeg</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">from pd_parser.parse_pd import _read_tsv</span>
<span class="sd">beh = _read_tsv(behf)</span>
<span class="sd">for i in range(annot.onset.size):  # skip the first video</span>
<span class="sd">    action_time = (beh[&#39;tone_onset&#39;][i] - beh[&#39;action_onset&#39;][i]) / 1000</span>
<span class="sd">    run([&#39;ffmpeg&#39;, &#39;-i&#39;, f&#39;{video_fname}&#39;, &#39;-ss&#39;,</span>
<span class="sd">         str(datetime.timedelta(</span>
<span class="sd">             seconds=annot.onset[i] - action_time - offset)),</span>
<span class="sd">         &#39;-to&#39;, str(datetime.timedelta(seconds=annot.onset[i] - offset)),</span>
<span class="sd">         op.join(out_dir, &#39;movement-{}+action_type-{}.mp4&#39;.format(</span>
<span class="sd">             beh[&#39;movement&#39;][i], beh[&#39;action_type&#39;][i]))])</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Here are the event times:  [ 19.051125    39.913       61.88575     83.5424375  104.4145625
 126.07720833 147.55397917 168.61270833 189.5784375  211.35672917
 250.20858333 271.68210417 292.14       313.30533333 333.78097917]

&quot;\nfrom pd_parser.parse_pd import _read_tsv\nbeh = _read_tsv(behf)\nfor i in range(annot.onset.size):  # skip the first video\n    action_time = (beh[&#39;tone_onset&#39;][i] - beh[&#39;action_onset&#39;][i]) / 1000\n    run([&#39;ffmpeg&#39;, &#39;-i&#39;, f&#39;{video_fname}&#39;, &#39;-ss&#39;,\n         str(datetime.timedelta(\n             seconds=annot.onset[i] - action_time - offset)),\n         &#39;-to&#39;, str(datetime.timedelta(seconds=annot.onset[i] - offset)),\n         op.join(out_dir, &#39;movement-{}+action_type-{}.mp4&#39;.format(\n             beh[&#39;movement&#39;][i], beh[&#39;action_type&#39;][i]))])\n&quot;
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  24.390 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-find-audio-events-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/81406c451e497331ddbbb284a4d8eb5b/plot_find_audio_events.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_find_audio_events.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/45db2a75d199d40435fefaab0063e78d/plot_find_audio_events.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_find_audio_events.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020, Alex Rockhill.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>